{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Video Frame to EEG Sample alignment method\n",
    "\n",
    "During initial investigations, we noticed that calculating the offset between the starting point of the EEG and the first TTL onset, and the start of the video recording and the frist LED onset is not enough. Somehow, there's either lag in the EEG recording, or the theoretical 30 FPS of the video recording is not reached in practice. Therefore we need a method that repairs this systematically increasing lag between the two in order to align them properly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cf05e945b82b4b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "import ndx_events\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:10:22.871102Z",
     "start_time": "2024-02-22T12:10:08.603941Z"
    }
   },
   "id": "c2e54840a4e576bc",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../settings.json', \"r\") as f:\n",
    "    settings = json.load(f)\n",
    "    \n",
    "epoch_folder = settings['epochs_folder']\n",
    "plot_folder = settings['plots_folder']\n",
    "nwb_folder = settings['nwb_files_folder']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:11:55.927729Z",
     "start_time": "2024-02-22T12:11:55.894544Z"
    }
   },
   "id": "9097ab9405c6dfa4",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create some handy converting functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d989e979958d93"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sample_to_frame(eeg_tp_in_secs, fps, offset):\n",
    "    \"\"\"\n",
    "    Function that calculates the time-point of the video (in frames) given\n",
    "     the time-point (in seconds) in the EEG.\n",
    "    \"\"\"\n",
    "    video_tp_secs = eeg_tp_in_secs - offset  # subtract the offset so we have the video tp in secs\n",
    "\n",
    "    return video_tp_secs * fps  # go to frames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:43:11.002314Z",
     "start_time": "2024-02-22T12:43:10.991357Z"
    }
   },
   "id": "dfdc2a6e40e6c202",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def frame_to_sample(frame_number, fps, offset):\n",
    "    \"\"\"\n",
    "    Function that calculates the time-point of the EEG (in secs) given\n",
    "     the video time-point in frames.\n",
    "    \"\"\"\n",
    "    tp_secs_video = frame_number / fps  # time-point on video in seconds\n",
    "    secs_eeg = tp_secs_video + offset\n",
    "    \n",
    "    return secs_eeg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:46:52.929680Z",
     "start_time": "2024-02-22T12:46:52.884454Z"
    }
   },
   "id": "7c6c0a96360a8e14",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading of needed info\n",
    "\n",
    "For the converting process we need a couple of things:\n",
    "* The EEG TTL onsets (which are in seconds)\n",
    "* A full EEG signal (does not matter which channel)\n",
    "* The sampling frequency of the EEG in the NWB file\n",
    "* The LED onset time-points (in frames)\n",
    "\n",
    "We do this only for a test subject that is manually selected."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d55fdca3fb10126"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_subject = \"80630\"  # is in batch 1 (see metadata excel sheets)\n",
    "video_filename = \"drd2_batch4_resting-state Camera 1 13-10-2023 09_29_44 1.mp4\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:19:10.803363Z",
     "start_time": "2024-02-22T12:19:10.790262Z"
    }
   },
   "id": "804bf907877ca6ed",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eeg_ttl_onsets_secs = []  # container (to make it accessible through notebook)\n",
    "\n",
    "for file in os.listdir(nwb_folder):\n",
    "    if test_subject in file and file.endswith(\".nwb\"):\n",
    "        with NWBHDF5IO(f'{nwb_folder}/{file}', \"r\") as io:  # open it\n",
    "            nwb = io.read()\n",
    "            eeg_ttl_onsets_secs = list(nwb.acquisition[\"TTL_1\"].timestamps)\n",
    "            s_freq = nwb.acquisition['raw_EEG'].rate\n",
    "            eeg_signal = filtered_eeg = nwb.acquisition['filtered_EEG'].data[:].T[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:19:39.160339Z",
     "start_time": "2024-02-22T12:19:11.212590Z"
    }
   },
   "id": "433aa5d2763c513a",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the TTL onset timepoints from the EEG of the test_subject, let's load the data that holds the LED ON timepoints from the accompanying video file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb7422f3bf3dfc6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "folder_path = \"/Users/olledejong/Documents/MSc_Biology/ResearchProject2/rp2_data/resting_state/output/videos\"\n",
    "pickle_path = f\"{folder_path}/pickle\"\n",
    "\n",
    "with open(f'{pickle_path}/led_states_all_videos.pickle', \"rb\") as f:\n",
    "    led_states = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:21:22.507319Z",
     "start_time": "2024-02-22T12:21:22.405729Z"
    }
   },
   "id": "2a0f95020e830893",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "led_states_data = led_states[video_filename]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:21:23.454869Z",
     "start_time": "2024-02-22T12:21:23.400201Z"
    }
   },
   "id": "52a6106bd1156a49",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only need the frame numbers where the LED switches ON, not all frames where the LED is ON."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75f61a892d69d667"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([   220,    250,    280, 548578, 548608, 548638])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "led_turns_on_indexes = np.where(np.logical_and(np.diff(led_states_data), led_states_data[1:]))[0] + 1  # get all False to True changes in the array\n",
    "led_turns_on_indexes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:34:41.642899Z",
     "start_time": "2024-02-22T12:34:41.497997Z"
    }
   },
   "id": "cbab49c8acf151b",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the frame number where the LED turns ON for the first time, we can calculate the needed offset.\n",
    "We calculate this by subtracting the time elapsed between start of **video** and the first LED onset from the time elapsed between start of **EEG** recording and the first TTL onset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bafcc35e9decce3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.66896666666667 8.663033675800019\n"
     ]
    }
   ],
   "source": [
    "video_fps = 30\n",
    "first_ttl_onset = eeg_ttl_onsets_secs[0]\n",
    "first_LED_onset = led_turns_on_indexes[0]\n",
    "\n",
    "offset_reg_fps = first_ttl_onset - first_LED_onset / video_fps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:22:18.657474Z",
     "start_time": "2024-02-22T12:22:18.631218Z"
    }
   },
   "id": "fb1b2a986f179d4e",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Try alignment with theoretical FPS\n",
    "Let's see how the aligning goes when we use the theoretical fps (30) and the offset that is calculated using that value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a7d861ce4d7d1b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onset 0. Actual EEG TTL onset: 16.0023, calculated: 15.996367009133351. Delta: 0.005932990866650556\n",
      "Onset 1. Actual EEG TTL onset: 17.0044, calculated: 16.99636700913335. Delta: 0.008032990866649214\n",
      "Onset 2. Actual EEG TTL onset: 18.0065, calculated: 17.99636700913335. Delta: 0.010132990866647873\n",
      "Onset 3. Actual EEG TTL onset: 18309.3886, calculated: 18294.596367009133. Delta: 14.792232990865159\n",
      "Onset 4. Actual EEG TTL onset: 18310.3898, calculated: 18295.596367009133. Delta: 14.793432990867586\n",
      "Onset 5. Actual EEG TTL onset: 18311.3919, calculated: 18296.596367009133. Delta: 14.795532990865468\n"
     ]
    }
   ],
   "source": [
    "for i, frame_led_on in enumerate(led_turns_on_indexes):\n",
    "    eeg_ttl_in_secs = frame_to_sample(frame_led_on, fps=video_fps, offset=offset_reg_fps)\n",
    "    print(f\"Onset {i}. Actual EEG TTL onset: {eeg_ttl_onsets_secs[i]}, calculated: {eeg_ttl_in_secs}. Delta: {eeg_ttl_onsets_secs[i] - eeg_ttl_in_secs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:22:38.815779Z",
     "start_time": "2024-02-22T12:22:38.790514Z"
    }
   },
   "id": "a4dbea78bd6503c0",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's try the other way around"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b54c09236be80"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onset 0. Actual frame LED onset: 220, calculated: -259.62642549504983\n",
      "Onset 1. Actual frame LED onset: 250, calculated: -259.5987104846194\n",
      "Onset 2. Actual frame LED onset: 280, calculated: -259.57099547418903\n",
      "Onset 3. Actual frame LED onset: 548578, calculated: 246.31249488425988\n",
      "Onset 4. Actual frame LED onset: 548608, calculated: 246.34018500345252\n",
      "Onset 5. Actual frame LED onset: 548638, calculated: 246.36790001388283\n"
     ]
    }
   ],
   "source": [
    "for i, eeg_ttl_onset in enumerate(eeg_ttl_onsets_secs):\n",
    "    frame_of_led_onset = sample_to_frame(eeg_ttl_onset, fps=video_fps, s_freq=s_freq, offset=offset_reg_fps)\n",
    "    print(f\"Onset {i}. Actual frame LED onset: {led_turns_on_indexes[i]}, calculated: {frame_of_led_onset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:25:46.183714Z",
     "start_time": "2024-02-22T12:25:46.161708Z"
    }
   },
   "id": "3674f6c22027eca4",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, let's try with the adjusted FPS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f94a74f369cb90e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets calculate the adjusted fps to account for the delay in either the video or eeg recording."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a5461625d51028"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "29.975748294429295"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find length of eeg signal between the two pulse combination. For example first and last\n",
    "eeg_len = eeg_signal[int(s_freq * eeg_ttl_onsets_secs[0]): int(s_freq * eeg_ttl_onsets_secs[-1])].shape[0]\n",
    "\n",
    "# find length of video frames between the two pulse combination\n",
    "frame_len = led_turns_on_indexes[-1] - led_turns_on_indexes[0]\n",
    "\n",
    "adjusted_fps = (frame_len / (eeg_len / s_freq))\n",
    "adjusted_fps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb334666e69ad00",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, the actual framerate is not exactly 30. Now, lets re-calculate the offset with this adjusted fps as well."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fd063cd0c533837"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "offset_adj_fps = first_ttl_onset - first_LED_onset / adjusted_fps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce79080b03901885"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And let's test the alignment of EEG and Video again"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db584a70a817e710"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onset 0. Actual EEG TTL onset: 16.0023, calculated: 16.0023\n",
      "Onset 1. Actual EEG TTL onset: 17.0044, calculated: 17.00310904420909\n",
      "Onset 2. Actual EEG TTL onset: 18.0065, calculated: 18.00391808841818\n",
      "Onset 3. Actual EEG TTL onset: 18309.3886, calculated: 18309.390495480246\n",
      "Onset 4. Actual EEG TTL onset: 18310.3898, calculated: 18310.391304524455\n",
      "Onset 5. Actual EEG TTL onset: 18311.3919, calculated: 18311.392113568665\n"
     ]
    }
   ],
   "source": [
    "for i, frame_led_on in enumerate(led_turns_on_indexes):\n",
    "    eeg_ttl_in_secs = frame_to_sample(frame_led_on, fps=adjusted_fps, offset=offset_adj_fps)\n",
    "    print(f\"Onset {i}. Actual EEG TTL onset: {eeg_ttl_onsets_secs[i]}, calculated: {eeg_ttl_in_secs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:26:53.445137Z",
     "start_time": "2024-02-22T12:26:53.419065Z"
    }
   },
   "id": "67eac85e0036778",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onset 0. Actual frame LED onset: 220, calculated: 220.0\n",
      "Onset 1. Actual frame LED onset: 250, calculated: 250.03869736584755\n",
      "Onset 2. Actual frame LED onset: 280, calculated: 280.0773947316951\n",
      "Onset 3. Actual frame LED onset: 548578, calculated: 548577.9431815612\n",
      "Onset 4. Actual frame LED onset: 548608, calculated: 548607.9549007537\n",
      "Onset 5. Actual frame LED onset: 548638, calculated: 548637.9935981195\n"
     ]
    }
   ],
   "source": [
    "for i, eeg_ttl_onset in enumerate(eeg_ttl_onsets_secs):\n",
    "    frame_of_led_onset = sample_to_frame(eeg_ttl_onset, fps=adjusted_fps, offset=offset_adj_fps)\n",
    "    print(f\"Onset {i}. Actual frame LED onset: {led_turns_on_indexes[i]}, calculated: {frame_of_led_onset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:35:35.397257Z",
     "start_time": "2024-02-22T12:35:35.378965Z"
    }
   },
   "id": "3952bed950d2ea04",
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
